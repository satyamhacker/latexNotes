# Module 18: Design Instagram/Newsfeed

## Topic 18.1: Newsfeed System - Feed Generation & Fanout

---

## üéØ 1. Title / Topic: Instagram/Newsfeed System (Timeline Generation)

---

## üê£ 2. Samjhane ke liye (Simple Analogy):

Newsfeed ek **Newspaper Delivery System** jaisa hai. Jaise newspaper office mein editor decide karta hai ki aapke ghar kaunse articles deliver karein (based on your interests), waise hi Instagram decide karta hai ki aapki feed mein kaunse posts dikhayein. **2 approaches:** (1) **Push (Fanout on Write):** Jaise newspaper subah print hoke sabke ghar deliver ho jata hai (ready to read), waise hi post create hote hi sabke feed mein push (fast read, slow write). (2) **Pull (Fanout on Read):** Jaise aap library jaake latest newspapers dhundte ho (slow read), waise hi feed open karne par posts fetch (fast write, slow read). Instagram uses **Hybrid** - celebrities ke liye Pull, normal users ke liye Push.

---

## üìñ 3. Technical Definition (Interview Answer):

**Newsfeed System** is a content aggregation and ranking platform that generates personalized timelines by collecting posts from followed users, applying ranking algorithms (chronological, ML-based), and delivering via fanout strategies (push/pull/hybrid) with caching for performance.

**Key terms:**
- **Fanout on Write (Push):** Post create ‚Üí Immediately push to all followers' feeds (pre-computed, fast read)
- **Fanout on Read (Pull):** User opens app ‚Üí Fetch posts from followed users (compute on demand, slow read)
- **Hybrid Fanout:** Celebrities (1M followers) ‚Üí Pull, Normal users (<5K followers) ‚Üí Push
- **Ranking Algorithm:** Chronological (time-based) vs ML-based (engagement prediction)
- **Feed Cache:** Redis stores recent posts (last 100) for fast retrieval (<10ms)

---

## üß† 4. Zaroorat Kyun Hai? (Why?):

**Main Problem:** User follows 500 people, har baar feed open karne par 500 users ke posts fetch karna slow hai (500 DB queries √ó 50ms = 25 seconds). Pre-computed feed (fanout on write) se <100ms mein ready.

**Business Impact:** Facebook study: 100ms delay = 1% engagement drop. Instagram: Personalized feed increased engagement 40% (vs chronological). TikTok: ML-based feed = 52 min avg daily usage (highest in industry).

**Technical Benefits:**
- **Fast Load:** Pre-computed feed <100ms (vs 25 sec on-demand)
- **Personalization:** ML ranking shows relevant posts first ‚Üí Higher engagement
- **Scalability:** Hybrid fanout handles celebrities (1M followers) efficiently
- **Real-time:** New posts appear in feed within seconds

---

## üö´ 5. Iske Bina Kya Hoga? (Failure Scenario):

**Scenario: No Pre-computed Feed (Pure Pull)**
- User follows 500 people
- Opens Instagram ‚Üí Fetch posts from 500 users
- Query: SELECT * FROM posts WHERE user_id IN (500 users) ORDER BY timestamp LIMIT 100
- Database: 500 users √ó 100 posts each = 50K posts to scan
- Time: 50K posts √ó 1ms = 50 seconds (unacceptable)
- User: Closes app, frustrated

**Real Example:** **Twitter (2010)** - Pure pull model ‚Üí Feed took 10+ seconds to load ‚Üí Users complained ‚Üí Switched to fanout on write (2011) ‚Üí Load time <1 sec ‚Üí Engagement increased 30%. **Instagram (2016)** - Switched from chronological to ML-ranked feed ‚Üí Engagement up 40%, but controversy (users wanted chronological back).

---

## ‚öôÔ∏è 6. Under the Hood (Technical Working):

**Fanout on Write (Push) Flow:**

1. **User Posts:** Alice posts photo "Sunset at beach"
2. **Fetch Followers:** Get Alice's followers list (10K followers)
3. **Fanout Workers:** Distribute to 10 workers (1K followers each)
4. **Push to Feeds:** Each worker inserts post into followers' feeds
   - Bob's feed: INSERT post_id into feed_bob
   - Charlie's feed: INSERT post_id into feed_charlie
   - ... (10K inserts)
5. **Cache Update:** Update Redis cache for active users
6. **Notification:** Send push notification to followers
7. **Total Time:** 10K inserts √ó 1ms = 10 seconds (async, user doesn't wait)

**Fanout on Read (Pull) Flow:**

1. **User Opens App:** Bob opens Instagram
2. **Fetch Following:** Get Bob's following list (500 users)
3. **Fetch Posts:** Query posts from 500 users (last 24 hours)
4. **Merge & Sort:** Combine posts, sort by timestamp
5. **Ranking:** Apply ML model (predict engagement score)
6. **Return Top 100:** Show in feed
7. **Total Time:** 500 queries + merge + rank = 5-10 seconds (slow)

**Hybrid Fanout (Best Approach):**

```
POST CREATION:
     |
     v
[Check User Type]
     |
     +---> Celebrity (>100K followers)?
     |          |
     |          v
     |     [Fanout on Read]
     |     Store post in user's timeline only
     |     Followers fetch when they open app
     |
     +---> Normal User (<100K followers)?
                |
                v
           [Fanout on Write]
           Push to all followers' feeds
           (Pre-compute for fast read)
```

**ASCII Architecture Diagram:**

```
[USER POSTS PHOTO]
     |
     v
+---------------------------+
|   POST SERVICE            |
|   - Validate image        |
|   - Store in S3           |
|   - Create post record    |
+---------------------------+
     |
     v
+---------------------------+
|   FANOUT SERVICE          |
|   (Decision Engine)       |
+---------------------------+
     |
     | Check follower count
     v
+---------------------------+
|   FOLLOWER GRAPH DB       |
|   (Social Graph)          |
|   user_id ‚Üí [followers]   |
+---------------------------+
     |
     +---> Followers < 100K? ‚Üí PUSH (Fanout on Write)
     |                              |
     |                              v
     |                    +---------------------------+
     |                    |   FANOUT WORKERS          |
     |                    |   (Parallel Processing)   |
     |                    +---------------------------+
     |                              |
     |                              v
     |                    +---------------------------+
     |                    |   FEED STORAGE            |
     |                    |   (Cassandra)             |
     |                    |   user_feed table         |
     |                    +---------------------------+
     |
     +---> Followers > 100K? ‚Üí PULL (Fanout on Read)
                                    |
                                    v
                          +---------------------------+
                          |   USER TIMELINE           |
                          |   (Store post only)       |
                          +---------------------------+


FEED RETRIEVAL FLOW:

[USER OPENS APP]
     |
     v
+---------------------------+
|   FEED SERVICE            |
+---------------------------+
     |
     | (1) Check Cache
     v
+---------------------------+
|   REDIS CACHE             |
|   feed:user123 ‚Üí [posts]  |
+---------------------------+
     |
     +---> Cache HIT? ‚Üí Return cached feed (10ms)
     |
     +---> Cache MISS? ‚Üí Continue
     |
     v
+---------------------------+
|   FEED STORAGE            |
|   (Cassandra)             |
|   SELECT * FROM user_feed |
|   WHERE user_id = 123     |
+---------------------------+
     |
     | (2) Fetch post details
     v
+---------------------------+
|   POST METADATA DB        |
|   (MySQL/PostgreSQL)      |
|   - Image URL, caption    |
|   - Likes, comments count |
+---------------------------+
     |
     | (3) Apply Ranking
     v
+---------------------------+
|   RANKING SERVICE         |
|   (ML Model)              |
|   - Engagement prediction |
|   - Personalization       |
+---------------------------+
     |
     | (4) Return Top 100
     v
[USER SEES FEED]


DETAILED FANOUT ON WRITE:

[Alice posts photo (10K followers)]
     |
     v
[Fanout Service]
     |
     | Split into batches (1K each)
     v
+--------+  +--------+  +--------+  +--------+
|Worker1 |  |Worker2 |  |Worker3 |  |Worker10|
|1-1K    |  |1K-2K   |  |2K-3K   |  |9K-10K  |
+--------+  +--------+  +--------+  +--------+
     |          |          |          |
     | Parallel execution (async)
     v          v          v          v
[Insert into each follower's feed]
     |
     v
Cassandra:
INSERT INTO user_feed (user_id, post_id, timestamp)
VALUES (follower1, post123, now())
VALUES (follower2, post123, now())
...
VALUES (follower10000, post123, now())

Time: 10K inserts / 10 workers = 1K inserts per worker
1K √ó 1ms = 1 second per worker (parallel)
Total: 1 second (vs 10 seconds sequential)
```

---

## üõ†Ô∏è 7. Problems Solved:

- **Fast Feed Load:** Pre-computed feed <100ms (vs 25 sec on-demand query) ‚Üí Better UX
- **Celebrity Problem:** Hybrid fanout handles 1M followers efficiently (pull instead of 1M writes)
- **Personalization:** ML ranking shows relevant posts ‚Üí 40% engagement increase (Instagram data)
- **Real-time Updates:** New posts appear in feed within seconds (fanout workers process async)
- **Scalability:** Horizontal scaling (add more fanout workers) ‚Üí Handle 1B posts/day
- **Storage Optimization:** Store only post_id in feed (not full post) ‚Üí 90% storage saved

---

## üåç 8. Real-World Example:

**Instagram Feed Architecture:** 1B+ users, 95M posts/day. Fanout: Hybrid (celebrities pull, normal users push). Storage: Cassandra for feeds (partition by user_id), PostgreSQL for post metadata. Ranking: ML model (TensorFlow) predicts engagement based on 1000+ signals (past likes, time spent, relationships). Cache: Redis stores last 100 posts per user (99% cache hit rate). Scale: 10K fanout workers process 1M posts/sec. Technology: Python backend, Cassandra (petabyte scale), Redis cluster (100+ nodes). Result: Feed loads in <100ms for 99% users. Without hybrid fanout, celebrities posting would take 10+ minutes to fanout to 100M followers.

---

## üîß 9. Tech Stack / Tools:

- **Cassandra:** Feed storage (user_feed table). Use for: Time-series data (posts sorted by timestamp), horizontal scaling (petabyte scale), high write throughput (1M writes/sec).

- **Redis:** Feed cache (last 100 posts). Use for: Fast retrieval (<10ms), 99% cache hit rate, sorted sets for ranked feeds.

- **Kafka:** Fanout queue. Use for: Async processing (fanout workers consume), guaranteed delivery, replay capability.

- **TensorFlow/PyTorch:** ML ranking model. Use for: Engagement prediction, personalization, A/B testing different ranking algorithms.

---

## üìê 10. Architecture/Formula:

**Fanout Decision Formula:**

```
Fanout_Strategy = 
    if follower_count > 100K: PULL
    elif follower_count > 10K: HYBRID (push to active, pull for inactive)
    else: PUSH

Reasoning:
- PUSH: 10K followers √ó 1ms = 10 sec (acceptable)
- PULL: 100K followers √ó 1ms = 100 sec (too slow)
- HYBRID: Push to 10K active users (online in last 24h), pull for 90K inactive
```

**Feed Storage Calculation:**

```
Storage_Per_User = Avg_Posts_Per_Day √ó Retention_Days √ó Post_Size

Example (Instagram scale):
Users = 1 billion
Avg_Posts_Per_Day = 100 (from 500 following)
Retention_Days = 30 days
Post_Size = 100 bytes (post_id + timestamp + metadata)

Storage_Per_User = 100 √ó 30 √ó 100 bytes = 300 KB
Total_Storage = 1B users √ó 300 KB = 300 TB

With compression (50%): 150 TB
With replication (3x): 450 TB
```

**Ranking Score Formula (Simplified):**

```
Engagement_Score = 
    (Likes √ó 1.0) + 
    (Comments √ó 2.0) + 
    (Shares √ó 3.0) + 
    (Time_Spent √ó 0.5) + 
    (Recency_Factor √ó 1.5) +
    (Relationship_Score √ó 2.0)

Where:
Recency_Factor = 1 / (hours_since_post + 1)
Relationship_Score = (past_interactions / total_posts) √ó 10

Example:
Post: 100 likes, 10 comments, 5 shares, 30 sec time spent, 2 hours old
User: 50 past interactions with poster (out of 200 posts)

Score = (100√ó1) + (10√ó2) + (5√ó3) + (30√ó0.5) + (1/(2+1)√ó1.5) + ((50/200)√ó10√ó2)
      = 100 + 20 + 15 + 15 + 0.5 + 5
      = 155.5

Higher score ‚Üí Higher rank in feed
```

**Cassandra Schema:**

```sql
-- User Feed Table (Pre-computed)
CREATE TABLE user_feed (
    user_id UUID,              -- Partition key
    post_id UUID,              -- Clustering key
    timestamp TIMESTAMP,       -- Clustering key (sort order)
    author_id UUID,
    PRIMARY KEY ((user_id), post_id, timestamp)
) WITH CLUSTERING ORDER BY (timestamp DESC);

-- Query: Get user's feed (last 100 posts)
SELECT * FROM user_feed
WHERE user_id = ?
ORDER BY timestamp DESC
LIMIT 100;

-- Efficient: Single partition read, sorted by timestamp
-- Latency: <10ms for 100 posts


-- Post Metadata Table
CREATE TABLE posts (
    post_id UUID PRIMARY KEY,
    author_id UUID,
    image_url TEXT,
    caption TEXT,
    likes_count INT,
    comments_count INT,
    created_at TIMESTAMP
);
```

---

## üíª 11. Code / Flowchart:

**Flowchart (Hybrid Fanout):**

```
START: User posts photo
  |
  v
[Store post in DB]
post_id = generate_uuid()
  |
  v
[Fetch followers]
followers = get_followers(user_id)
count = len(followers)
  |
  v
[Decision: Fanout strategy]
  |
  +---> count > 100K? ‚Üí PULL
  |          |
  |          v
  |     [Store in user timeline only]
  |     [Followers fetch on demand]
  |
  +---> count < 100K? ‚Üí PUSH
             |
             v
        [Fanout to all followers]
             |
             v
        [Split into batches]
        batches = split(followers, 1000)
             |
             v
        [Parallel workers]
        for batch in batches:
            worker.process(batch, post_id)
             |
             v
        [Insert into feeds]
        for follower in batch:
            INSERT INTO user_feed
            (follower, post_id, timestamp)
  |
  v
END
```

**Code (Simplified Feed Service):**

```python
# Import typing for type hints (helps with code clarity and IDE autocomplete)
from typing import List

# Import redis for feed caching and storage (fast in-memory data structure store)
# Redis used for: Sorted sets (feed with timestamps), fast retrieval (<10ms)
import redis

# Import time for timestamp generation (Unix timestamp for post ordering)
import time

class FeedService:
    def __init__(self):
        """
        Initialize Feed Service
        Sets up Redis connection and fanout threshold
        """
        # Redis client for feed storage and caching
        # Why Redis? Fast sorted sets (ZADD, ZREVRANGE), in-memory (<10ms vs 500ms DB)
        # Production: Use Redis Cluster for high availability (multiple nodes)
        self.redis = redis.Redis(host='localhost', port=6379)
        
        # Fanout threshold: Celebrity vs Normal user decision boundary
        # 100K followers = 100,000 √ó 1ms insert = 100 seconds fanout time
        # Above this: Too slow for Push (use Pull instead)
        # Below this: Acceptable for Push (pre-compute feeds)
        self.fanout_threshold = 100000  # 100K followers
    
    def create_post(self, user_id: str, post_id: str):
        """
        Handle new post creation and fanout to followers
        Flow: Get followers ‚Üí Check count ‚Üí Push (normal) or Pull (celebrity)
        
        user_id: Who created the post (e.g., "alice")
        post_id: Unique post identifier (e.g., "post123")
        """
        # STEP 1: Fetch followers list from social graph database
        # Production: Query Neo4j/PostgreSQL graph table
        # Query: SELECT follower_id FROM followers WHERE user_id = ?
        # Returns: List of follower IDs (e.g., ["bob", "charlie", ...])
        followers = self.get_followers(user_id)
        
        # STEP 2: Decide fanout strategy based on follower count
        # Decision logic: Celebrity (>100K) vs Normal user (<100K)
        if len(followers) > self.fanout_threshold:
            # ===== CELEBRITY PATH (Fanout on Read - PULL) =====
            # Problem: 1M followers √ó 1ms = 1000 seconds (16 minutes) to fanout
            # Solution: Store post in user's timeline only, followers fetch on demand
            # When follower opens app: Query celebrity's timeline, pull recent posts
            # Benefit: Fast write (instant), slow read (acceptable for pull)
            self._store_in_timeline(user_id, post_id)
        else:
            # ===== NORMAL USER PATH (Fanout on Write - PUSH) =====
            # Acceptable: 10K followers √ó 1ms = 10 seconds (manageable)
            # Strategy: Pre-compute feeds (push to all followers' feeds)
            # When follower opens app: Feed already ready (<10ms retrieval)
            # Benefit: Fast read (<100ms), slow write (10 sec, but async - user doesn't wait)
            self._fanout_to_followers(followers, post_id)
    
    def _fanout_to_followers(self, followers: List[str], post_id: str):
        """
        Push post to all followers' feeds (Fanout on Write)
        Uses batch processing for parallel execution
        
        followers: List of follower user IDs (e.g., ["bob", "charlie", ...])
        post_id: Post to insert into feeds (e.g., "post123")
        """
        # Batch size: Process 1000 followers at a time
        # Why 1000? Balance between parallelism and memory usage
        # Too small (100): Too many batches, overhead increases
        # Too large (10K): High memory usage, slower per batch
        # 1000 = sweet spot for most systems
        batch_size = 1000
        
        # Process followers in batches (parallel execution in production)
        # range(start, stop, step): e.g., range(0, 10000, 1000) ‚Üí [0, 1000, 2000, ...]
        for i in range(0, len(followers), batch_size):
            # Extract batch: followers[0:1000], followers[1000:2000], etc.
            # Python slice: list[start:end] (end is exclusive)
            batch = followers[i:i+batch_size]
            
            # Production: Use Celery/Kafka for parallel processing
            # Celery: Distributed task queue (async workers)
            # Kafka: Message queue (workers consume batches in parallel)
            # Here: Simplified synchronous processing for demonstration
            # In production: 10 workers process 10 batches simultaneously
            # Time: 10K followers / 10 workers = 1K per worker √ó 1ms = 1 second
            for follower_id in batch:
                # Insert post into each follower's feed
                # This is the core "fanout" operation (1 post ‚Üí N feeds)
                self._insert_into_feed(follower_id, post_id)
    
    def _insert_into_feed(self, user_id: str, post_id: str):
        """
        Insert post into user's feed (Redis sorted set)
        Feed structure: Sorted by timestamp (reverse chronological)
        
        user_id: Feed owner (e.g., "bob")
        post_id: Post to add (e.g., "post123")
        """
        # Generate timestamp (score for sorted set)
        # time.time() = Unix timestamp (seconds since Jan 1, 1970)
        # Example: 1640000000.123456 (float with microseconds)
        # Used as score in sorted set (higher timestamp = newer post = higher rank)
        timestamp = time.time()
        
        # Redis ZADD: Add member to sorted set with score
        # Command: ZADD key score member
        # Key: "feed:bob" (user's feed identifier)
        # Score: timestamp (1640000000.123456)
        # Member: post_id ("post123")
        # Result: Sorted set with posts ordered by timestamp
        # Why sorted set? Automatic sorting, O(log N) insert, range queries
        self.redis.zadd(f"feed:{user_id}", {post_id: timestamp})
        
        # Keep only last 1000 posts per user (memory management)
        # ZREMRANGEBYRANK: Remove members by rank range
        # Ranks: 0 (lowest score/oldest) to -1 (highest score/newest)
        # Keep: Rank -1000 to -1 (last 1000 posts)
        # Remove: Rank 0 to -1001 (all posts except last 1000)
        # Why 1000? Most users scroll <100 posts, 1000 = safety buffer
        # Storage: 1000 posts √ó 16 bytes (UUID) = 16 KB per user
        # For 1B users: 16 TB (affordable)
        self.redis.zremrangebyrank(f"feed:{user_id}", 0, -1001)
    
    def get_feed(self, user_id: str, limit: int = 100) -> List[str]:
        """
        Get user's feed (cached or from database)
        Flow: Check Redis cache ‚Üí Return if hit ‚Üí Fetch from DB if miss
        
        user_id: Feed owner (e.g., "bob")
        limit: Number of posts to return (default 100)
        Returns: List of post IDs in reverse chronological order
        """
        # STEP 1: Check Redis cache first (99% cache hit rate in production)
        # ZREVRANGE: Get members in reverse order (newest first)
        # Command: ZREVRANGE key start stop
        # Start: 0 (highest rank/newest post)
        # Stop: limit-1 (e.g., 99 for 100 posts)
        # Returns: List of post_ids in bytes (e.g., [b'post123', b'post122', ...])
        # Why reverse? Show newest posts first (Instagram, Twitter standard)
        cached = self.redis.zrevrange(f"feed:{user_id}", 0, limit-1)
        
        if cached:
            # Cache HIT: Feed found in Redis
            # Latency: <10ms (in-memory retrieval)
            # Decode: Convert bytes to strings (b'post123' ‚Üí 'post123')
            # List comprehension: [x.decode() for x in cached]
            # Returns: ["post123", "post122", ...] (sorted by timestamp, newest first)
            return [post_id.decode() for post_id in cached]
        
        # Cache MISS: Feed not in Redis (rare - 1% of requests)
        # Reasons: User inactive (cache expired), new user, cache cleared
        # Fallback: Fetch from database (Cassandra in production)
        # For celebrities: This triggers Fanout on Read (pull from following users)
        # Latency: 500ms (database query vs 10ms cache)
        return self._fetch_from_db(user_id, limit)
    
    def _fetch_from_db(self, user_id: str, limit: int) -> List[str]:
        """
        Fetch feed from database (Cassandra in production)
        This is where Fanout on Read happens for celebrities
        
        user_id: Feed owner
        limit: Number of posts to fetch
        Returns: List of post IDs
        """
        # Production Cassandra query:
        # SELECT post_id FROM user_feed 
        # WHERE user_id = ? 
        # ORDER BY timestamp DESC 
        # LIMIT ?
        # 
        # For celebrities (Fanout on Read):
        # 1. Get following list (e.g., 500 users)
        # 2. Fetch recent posts from each following user
        # 3. Merge and sort by timestamp
        # 4. Apply ML ranking (engagement prediction)
        # 5. Return top 100
        # 
        # Time: 500 users √ó 10ms = 5 seconds (acceptable for celebrities)
        # Optimization: Parallel queries (10 workers √ó 50 users = 500ms)
        
        return []  # Mock implementation (empty list for demonstration)
    
    def get_followers(self, user_id: str) -> List[str]:
        """
        Get user's followers from social graph database
        Production: Query Neo4j/PostgreSQL graph table
        
        user_id: User whose followers to fetch
        Returns: List of follower IDs
        """
        # Production query (PostgreSQL):
        # SELECT follower_id FROM followers 
        # WHERE user_id = ?
        # 
        # Or Neo4j (graph database):
        # MATCH (u:User {id: ?})<-[:FOLLOWS]-(follower)
        # RETURN follower.id
        # 
        # Result: ["bob", "charlie", "david", ...]
        # Count determines fanout strategy (>100K ‚Üí pull, <100K ‚Üí push)
        
        # Mock: Return 10K followers for demonstration
        # In production, this would be a real database query
        return [f"user{i}" for i in range(10000)]  # 10K followers

# ============ USAGE EXAMPLES ============

# Initialize service
service = FeedService()

# Example 1: Normal user posts (10K followers - PUSH strategy)
service.create_post(user_id="alice", post_id="post123")
# Flow:
# 1. Get alice's followers: 10K users
# 2. Check: 10K < 100K ‚Üí PUSH (Fanout on Write)
# 3. Batch processing: 10 batches √ó 1K followers
# 4. Insert post123 into 10K feeds (parallel workers in production)
# 5. Time: 1 second (async, alice doesn't wait)
# 6. Followers open app ‚Üí Feed ready (<10ms Redis retrieval)

# Example 2: Celebrity posts (1M followers - PULL strategy)
# service.create_post(user_id="celebrity", post_id="post456")
# Flow:
# 1. Get celebrity's followers: 1M users
# 2. Check: 1M > 100K ‚Üí PULL (Fanout on Read)
# 3. Store post456 in celebrity's timeline only
# 4. Time: Instant (no fanout)
# 5. Followers open app ‚Üí Pull from celebrity's timeline on demand
# 6. Time: 500ms (acceptable for pull)

# Example 3: User gets feed (cached - FAST)
feed = service.get_feed(user_id="bob", limit=100)
print(f"Bob's feed: {len(feed)} posts")
# Flow:
# 1. Check Redis: "feed:bob"
# 2. ZREVRANGE feed:bob 0 99
# 3. Cache HIT: Return 100 post IDs
# 4. Time: <10ms
# Output: Bob's feed: 100 posts

# Example 4: Cache miss scenario (new user - SLOW)
# feed = service.get_feed(user_id="new_user", limit=100)
# Flow:
# 1. Check Redis: "feed:new_user"
# 2. Cache MISS: Not found
# 3. Fallback: Query Cassandra/Database
# 4. For normal user: Fetch from user_feed table
# 5. For celebrity follower: Fanout on Read (pull from following users)
# 6. Time: 500ms (database query)


# ============ PRODUCTION CONSIDERATIONS ============

"""
1. PARALLEL PROCESSING (Celery/Kafka):
   - Current: Sequential batch processing
   - Production: 10 workers process 10 batches simultaneously
   - Time: 10K followers / 10 workers = 1K per worker √ó 1ms = 1 second

2. DATABASE CHOICE:
   - Feed storage: Cassandra (time-series optimized, petabyte scale)
   - Post metadata: PostgreSQL (ACID, relational)
   - Social graph: Neo4j (graph queries) or PostgreSQL (adjacency list)

3. CACHING STRATEGY:
   - Cache: Last 1000 posts per user (16 KB)
   - TTL: 24 hours (refresh daily)
   - Invalidation: New post ‚Üí Append to cache (ZADD)
   - Hit rate: 99% (most users see cached feed)

4. ML RANKING:
   - After fetching posts, apply ML model
   - Features: Past likes, time spent, relationship score, recency
   - Score = weighted sum of features
   - Sort by score (highest first)
   - Use TensorFlow/PyTorch for inference

5. ASYNC FANOUT:
   - User posts ‚Üí Immediately return success
   - Background workers (Celery) process fanout
   - User doesn't wait for 10 sec fanout
   - Better UX (instant post confirmation)

6. MONITORING:
   - Track: Fanout time, cache hit rate, feed load time
   - Alerts: If fanout >30 sec, cache hit rate <95%
   - Tools: Prometheus metrics, Grafana dashboards
"""
```
```

---

## üìà 12. Trade-offs:

- **Gain:** Fast feed load (<100ms), personalized content (ML ranking), real-time updates | **Loss:** Storage cost (300TB for 1B users), fanout delay (10 sec for 10K followers), complexity (hybrid strategy)

- **Gain:** Fanout on Write (fast read), Fanout on Read (fast write) | **Loss:** Push: Slow write (10K inserts), Pull: Slow read (500 queries), Hybrid: Complex logic

- **Gain:** ML ranking increases engagement 40% | **Loss:** Controversy (users want chronological), filter bubble (echo chamber), compute cost (ML inference expensive)

- **When to use:** Social media (Instagram, Facebook), news aggregation (Flipboard), content platforms (Medium) | **When to skip:** Simple blogs (chronological sufficient), low traffic (<1K users), no personalization needed

---

## üêû 13. Common Mistakes:

- **Mistake:** Pure fanout on write for all users (including celebrities)
  - **Why wrong:** Celebrity with 10M followers ‚Üí 10M feed inserts ‚Üí 10,000 seconds (3 hours)
  - **What happens:** Post creation times out, followers don't see post for hours
  - **Fix:** Hybrid fanout (celebrities use pull, normal users use push)

- **Mistake:** Storing full post in feed (image, caption, metadata)
  - **Why wrong:** 1KB post √ó 100 posts √ó 1B users = 100 TB (vs 10 TB with post_id only)
  - **What happens:** Storage explosion, slow queries (large rows)
  - **Fix:** Store only post_id in feed, fetch details separately

- **Mistake:** No caching (every feed request queries database)
  - **Why wrong:** 1M users √ó 10 feed opens/day = 10M DB queries/day
  - **What happens:** Database overload, slow feed load (500ms vs 10ms cached)
  - **Fix:** Redis cache with 99% hit rate (last 100 posts per user)

- **Mistake:** Synchronous fanout (user waits for fanout to complete)
  - **Why wrong:** 10K followers √ó 1ms = 10 sec ‚Üí User waits 10 sec after posting
  - **What happens:** Poor UX, user thinks post failed
  - **Fix:** Async fanout (Kafka queue, workers process in background)

---

## ‚úÖ 14. Zaroori Notes for Interview:

**Must Mention Points:**
1. **Start with fanout strategies:** "3 approaches hain - Push (fanout on write - fast read, slow write), Pull (fanout on read - fast write, slow read), Hybrid (best - celebrities pull, normal users push)."

2. **Draw architecture:** User posts ‚Üí Fanout service ‚Üí Check follower count ‚Üí Push (<100K) or Pull (>100K) ‚Üí Feed storage (Cassandra) ‚Üí Redis cache ‚Üí User retrieves feed.

3. **Explain hybrid decision:** "Follower count > 100K ‚Üí Pull (celebrity), < 100K ‚Üí Push (normal user). Reason: 100K √ó 1ms = 100 sec fanout time (too slow)."

4. **Common follow-ups:**
   - **"Fanout on write vs read?"** ‚Üí Write: Pre-compute (fast read <100ms, slow write 10 sec). Read: On-demand (fast write instant, slow read 5-10 sec). Hybrid best.
   - **"Celebrity problem kaise solve?"** ‚Üí Hybrid fanout. Celebrity posts ‚Üí Store in timeline only, followers fetch on demand (pull). Normal users ‚Üí Push to all followers.
   - **"Ranking algorithm kaise?"** ‚Üí ML model predicts engagement. Features: Past likes, time spent, relationship score, recency. Score = weighted sum. Higher score ‚Üí Higher rank.
   - **"Storage kaise optimize?"** ‚Üí Store only post_id in feed (not full post). Fetch details separately. 90% storage saved (100 bytes vs 1KB).

5. **Mention scale:** "Instagram: 1B users, 95M posts/day, <100ms feed load, 99% cache hit rate (Redis)."

6. **Pro tip:** "Interview mein hybrid fanout ka decision tree draw karo (follower count check). Aur mention karo - Async fanout (Kafka workers), Redis cache (99% hit rate), ML ranking (engagement prediction)."

---

## ‚ùì 15. FAQ & Comparisons (MANDATORY - 5 Questions):

**Q1: Fanout on Write vs Fanout on Read - Kab kaunsa use karein?**
A: **Fanout on Write (Push):** Post create ‚Üí Immediately push to all followers' feeds. **Pros:** Fast read (<100ms), **Cons:** Slow write (10K followers = 10 sec). **Use:** Normal users (<100K followers), read-heavy systems. **Fanout on Read (Pull):** User opens app ‚Üí Fetch posts from following users. **Pros:** Fast write (instant), **Cons:** Slow read (500 queries = 5-10 sec). **Use:** Celebrities (>100K followers), write-heavy systems. **Best:** Hybrid (Instagram, Twitter use this) - Push for normal, Pull for celebrities.

**Q2: Chronological feed vs ML-ranked feed - Trade-off kya hai?**
A: **Chronological:** Posts sorted by time (latest first). **Pros:** Simple, transparent, no filter bubble. **Cons:** Miss important posts (if not online), low engagement (irrelevant posts shown). **ML-Ranked:** Posts sorted by predicted engagement. **Pros:** 40% higher engagement (Instagram data), personalized, relevant content first. **Cons:** Filter bubble (echo chamber), controversy (users want control), compute cost (ML inference). **Best:** Hybrid - Default ML-ranked with option to switch to chronological (Instagram added this after user backlash).

**Q3: Feed storage mein Cassandra vs MySQL - Kaunsa better?**
A: **Cassandra:** NoSQL, time-series optimized (posts sorted by timestamp), horizontal scaling (petabyte scale), high write throughput (1M writes/sec). **Pros:** Scales to billions of users, fast writes (fanout). **Cons:** Eventual consistency, complex queries limited. **MySQL:** Relational, ACID, complex queries easy. **Pros:** Strong consistency, familiar SQL. **Cons:** Vertical scaling only (limited to 10TB), slow writes at scale. **Best:** Cassandra for feed storage (Instagram, Netflix use it). MySQL for post metadata (likes, comments - needs ACID).

**Q4: Feed cache strategy - Kya cache karein aur kitna?**
A: **What to cache:** Last 100 posts per user (post_ids only, not full posts). **Why 100:** 99% users scroll <100 posts per session. **Storage:** 100 posts √ó 16 bytes (UUID) √ó 1B users = 1.6 TB (affordable). **TTL:** 24 hours (refresh daily). **Cache hit rate:** 99% (most users see cached feed). **Invalidation:** New post ‚Üí Invalidate cache for followers (or append to cache). **Redis structure:** Sorted Set (ZADD with timestamp score). **Benefit:** 10ms cached vs 500ms DB query (50x faster).

**Q5: Group/Page posts kaise handle karein (1M members)?**
A: **Problem:** Page with 1M members posts ‚Üí 1M feed inserts (fanout on write) = 1000 sec (too slow). **Solution:** Hybrid approach - (1) **Active members** (<10K online in last 24h) ‚Üí Push to feeds, (2) **Inactive members** (990K) ‚Üí Pull on demand. **Implementation:** Track active users (Redis), fanout only to active. **Alternative:** Separate "Groups" tab (pull-based) vs "Home" feed (push-based). **Facebook approach:** Groups use pull, personal feed uses push. **Benefit:** Fast post creation (<10 sec), active users see immediately, inactive users fetch when they open.

---

## üéØ Module 18 Complete Summary:

**All Topics Covered:** 1/1 ‚úÖ
- ‚úÖ Topic 18.1: Instagram/Newsfeed System - Fanout Strategies (Push/Pull/Hybrid), Feed Storage (Cassandra), ML Ranking, Caching

**Key Takeaways:**
1. **Fanout Strategies:** Push (fast read, slow write), Pull (fast write, slow read), Hybrid (best - celebrities pull, normal users push)
2. **Hybrid Decision:** Follower count > 100K ‚Üí Pull, < 100K ‚Üí Push (100K √ó 1ms = 100 sec threshold)
3. **Storage:** Cassandra for feeds (time-series, petabyte scale), store only post_id (90% storage saved)
4. **Caching:** Redis stores last 100 posts per user (99% cache hit rate, <10ms retrieval)
5. **ML Ranking:** Engagement prediction based on 1000+ signals (40% engagement increase)

**Interview Focus:**
- Draw hybrid fanout decision tree (follower count check)
- Explain fanout on write vs read with examples
- Discuss celebrity problem and solution (pull instead of push)
- Mention async fanout (Kafka workers, non-blocking)
- Real-world: Instagram (1B users, 95M posts/day, <100ms feed load)

**Progress:** 18/21 Modules Completed üéâ

**Next Module:** Module 19 - Design YouTube/Netflix (Video Streaming, HLS, CDN)

---
